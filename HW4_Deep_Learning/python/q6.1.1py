import matplotlib.pyplot as plt
import numpy as np
import scipy.io 
import torch
import torch.nn.functional as F
from torch import optim, nn

# Load data
train_data = scipy.io.loadmat('../data/nist36_train.mat')
valid_data = scipy.io.loadmat('../data/nist36_valid.mat')
test_data = scipy.io.loadmat('../data/nist36_test.mat')

# Get data
train_x, train_y = train_data['train_data'], train_data['train_labels']
valid_x, valid_y = valid_data['valid_data'], valid_data['valid_labels']
test_x, test_y = test_data['test_data'], test_data['test_labels']

# Convert to tensor
train_x = torch.from_numpy(train_x).float()
train_y = torch.from_numpy(train_y).argmax(dim=1).long()
valid_x = torch.from_numpy(valid_x).float()
valid_y = torch.from_numpy(valid_y).argmax(dim=1).long()
test_x = torch.from_numpy(test_x).float()
test_y = torch.from_numpy(test_y).argmax(dim=1).long()

# Define model parameters
learning_rate = 0.003
max_iters = 50
batch_size = 32
hidden_size = 64
num_classes = 36
# loss_fn = nn.CrossEntropyLoss()

# Define model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(train_x.shape[1], hidden_size)
        self.act1 = nn.ReLU()
        # self.act2 = nn.Sigmoid()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = self.fc1(x)
        x = self.act1(x)
        x = self.fc2(x)
        return x

# Initialize model 
model = Net()

# Optimizer
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training
train_loss = []
train_acc = []
valid_loss = []
valid_acc = []

for epoch in range(max_iters):
    model.train()
    optimizer.zero_grad()
    y_pred = model(train_x)
    loss = F.cross_entropy(y_pred, train_y)
    loss.backward()
    optimizer.step()
    train_loss.append(loss.item())
    train_acc.append((y_pred.argmax(dim=1) == train_y).float().mean().item())
    
    
    model.eval()
    y_pred = model(valid_x)
    loss = F.cross_entropy(y_pred, valid_y)
    valid_loss.append(loss.item())
    valid_acc.append((y_pred.argmax(dim=1) == valid_y).float().mean().item())
    
    print("itr: {:02d} \t loss: {:.2f} \t acc : {:.2f}".format(epoch, train_loss[-1], train_acc[-1]))


# plot loss curves
plt.plot(range(len(train_loss)), train_loss, label="training")
plt.plot(range(len(valid_loss)), valid_loss, label="validation")
plt.xlabel("epoch")
plt.ylabel("average loss")
plt.xlim(0, len(train_loss) - 1)
# plt.xlim(0, 50)
plt.ylim(0, None)
plt.legend()
plt.grid()
plt.show()

# plot accuracy curves
plt.plot(range(len(train_acc)), train_acc, label="training")
plt.plot(range(len(valid_acc)), valid_acc, label="validation")
plt.xlabel("epoch")
plt.ylabel("accuracy")
plt.xlim(0, len(train_acc) - 1)
# plt.xlim(0, 50)
plt.ylim(0, None)
plt.legend()
plt.grid()
plt.show()
